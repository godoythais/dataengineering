# Pipeline de Transforma√ß√£o de Vendas (Data Engineering)

Este projeto cont√©m a orquestra√ß√£o e as transforma√ß√µes SQL para consolidar dados de vendas no Google BigQuery, gerando tabelas da camada "Gold" para an√°lise.

## üìã Vis√£o Geral

O pipeline √© orquestrado via **Apache Airflow** e executa scripts SQL utilizando o utilit√°rio de linha de comando `bq` do Google Cloud. O processo l√™ dados da tabela bruta (`table_sales`) e gera agrega√ß√µes por diferentes dimens√µes (marca, linha, tempo).

## üöÄ DAG: gold_sales_transform

- **Arquivo:** `dag_sales_transform.py`
- **ID da DAG:** `gold_sales_transform`
- **Schedule:** Diariamente √†s 09:00 (`0 9 * * *`).
- **Owner:** airflow
- **Depend√™ncias:** N√£o depende de execu√ß√µes passadas (`depends_on_past=False`).

### Fluxo de Execu√ß√£o
A DAG executa 4 tarefas em paralelo, cada uma respons√°vel por criar uma tabela de agrega√ß√£o espec√≠fica:

```mermaid
graph LR
    start[Start] --> t1[run_sales_by_month_year]
    start --> t2[run_sales_by_line_brand]
    start --> t3[run_sales_by_line]
    start --> t4[run_sales_by_brand]
    t1 --> end_task[End]
    t2 --> end_task
    t3 --> end_task
    t4 --> end_task
```

## üìä Transforma√ß√µes SQL

Os scripts SQL aplicam agrega√ß√µes (`SUM`, `GROUP BY`) e extra√ß√µes de data (`EXTRACT YEAR/MONTH`) para criar as seguintes tabelas de destino no BigQuery:

| Arquivo SQL | Tabela de Destino | Descri√ß√£o | Colunas Chave |
|---|---|---|---|
| `sales_by_brand.sql` | `gold_sales_by_brand` | Vendas agregadas por **Marca** ao longo do tempo. | `marca`, `ano`, `mes`, `qtd_venda` |
| `sales_by_line.sql` | `gold_sales_by_line` | Vendas agregadas por **Linha** de produto ao longo do tempo. | `linha`, `ano`, `mes`, `qtd_venda` |
| `sales_by_line_brand.sql` | `gold_sales_by_line_brand` | Vendas totais por **Marca e Linha**. | `marca`, `linha`, `qtd_venda` |
| `sales_by_month_year.sql` | `gold_sales_by_month_year` | Vendas totais por **Ano e M√™s** (vis√£o temporal geral). | `ano`, `mes`, `qtd_venda` |

## ‚öôÔ∏è Configura√ß√£o

### Estrutura de Pastas Esperada pela DAG
A DAG est√° configurada para buscar arquivos nos seguintes caminhos relativos:

```
.
‚îú‚îÄ‚îÄ dag_sales_transform.py
‚îú‚îÄ‚îÄ ../credenciais.json           # Arquivo de credenciais do GCP
‚îî‚îÄ‚îÄ ../example_dags/sql/          # Diret√≥rio contendo os arquivos .sql
    ‚îú‚îÄ‚îÄ sales_by_month_year.sql
    ‚îú‚îÄ‚îÄ sales_by_line_brand.sql
    ‚îú‚îÄ‚îÄ sales_by_line.sql
    ‚îî‚îÄ‚îÄ sales_by_brand.sql
```

> **Nota:** Verifique se as vari√°veis `GOOGLE_CREDENTIALS_PATH` e `BASE_SQL_DIR` no arquivo `.py` correspondem √† estrutura real do seu ambiente de implanta√ß√£o.

### Requisitos
- **Apache Airflow**: Para orquestra√ß√£o.
- **Google Cloud SDK**: Necess√°rio ter o comando `bq` dispon√≠vel no path.
- **Service Account**: Arquivo JSON com permiss√µes de leitura/escrita no BigQuery.
